---
title: ASR8:GMM to DNN
layout: post
tags:
  - speech_recognition
  - dnn
---

之前的模型是GMM+HMM，用高斯混合模型表示state，HMM解码。近两年深度学习非常火热，语音识别中也用DNN代替了GMM。

使用GMM的目的是对每一个state，算出它生成每个frame的概率，即p(x|y)，x代表观测到的frame，y代表state。这其实可以看作一个分类问题，把每个frame归为一个类，即计算p(y|x)，p(x|y)=p(y|x)*p(x)/p(y)，p(x)是固定的，所以我们用DNN得到p(y|x)，就可以根据 p(x|y)=p(y|x)/p(y)算出p(x|y)。

下面的问题就是怎么用DNN训练一个分类器。简单来说DNN就是一个多层的网络，每一层的输出都是输入的线性组合，y=wx+b，然后经过一个非线性变换作为下一层的输入，非线性变换常用的有sigmoid函数，tanh函数，最近RELU用的比较多，即y=max(x,0)。然后最后算出损失函数，分类问题损失函数可以用cross entropy作为损失函数，然后算出来损失用随机梯度下降最小化损失函数，更新参数，使用反向传播算法计算梯度下降中的偏导数。大概过程就是这样，其中还有很多细节和tricks。

再讲一下CNN，CNN是DNN的加强版，多用于图像识别。它的两大特点是局部连接和参数共享。提出了卷积层(conv)和池化层(pooling)，首先将输入与卷积核(kernel)做卷积，比如输入是128x128的图像，卷积核的大小为5x5，从原始图像中找一个5x5的区域和卷积核卷积，得到一个值，然后经过一定步长(stride)，再找另一个5x5区域做卷积，这样就得到做完卷积后的一个矩阵，所谓局部连接就是卷积层的一个点只与输入层5x5的区域连接，参数共享指每个5x5的区域都与同一个卷积核做卷积。当然一般一个卷积层会有几十个卷积核，这样得到的输出就是几十个做完卷积的图像。池化层很简单，就是把之前的图像变小，比如输入是100x100，池化层把每个2x2的区域变成1个像素点，步长为2的话最后就变成了50x50。CNN与DNN的区别主要就是这些，一般CNN前几层是局部连接的卷积层，最后几层才是全连接层。

知道了DNN，我们就可以用语音数据训练模型了。训练数据每个frame所属的state是有标注的，输入是每个frame的特征(MFCC/fMLLR/FBank)，最后用softmax算出frame属于每个state的概率，然后损失函数是cross entropy，迭代更新模型参数。训练结束后再输入frame特征就能得到属于每个state的概率了。

到这里大概知道了把DNN用到语音识别中的方法，当然其中还有很多技巧每一步也有很多选择和可以优化的地方，具体的还要读论文。