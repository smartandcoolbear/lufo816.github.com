---
title: IPN播客爬虫
layout: post
tags:
  - python
---

[李明](http://jie.sysu.edu.cn/~mli/)老师要做个语音识别的演示需要爬些语音数据，正好[IPN播客网络](http://ipn.li/)满足要求，于是就写了个爬虫可以爬下上面所有的语音，很简单，稍微改下可以改成多线程（不过这里的瓶颈是带宽不是延迟，改成多线程好像并没有什么用）。顺便推荐下IPN，节目质量很高。吐槽下可以爬的语音数据太少，都被荔枝FM这种大平台掌握着，所以还是要有自己的网站，不能只依靠其他平台，至少方便我们爬数据啊!XD，另外最好用静态网站哈哈。下面是代码：

{% highlight python %}

# -*- coding: utf-8 -*-

__author__ = 'lufo'

import os

import requests

from bs4 import BeautifulSoup

root_url = 'http://ipn.li/'



def get_podcast_list():

``` 
"""
获取ipn.li下面所有节目的链接
:return: 列表，每个元素为一个节目的链接
"""
global root_url
podcast_list = []
try:
    soup = BeautifulSoup(requests.get(root_url).content)
except Exception, e:
    print e
for item in soup.find_all('a', class_='showList__item__head'):
    podcast_list.append(os.path.join(root_url, item['href']))
return podcast_list
```

def get_download_url_list(url):

``` 
"""
获取一个节目已经播出的播客下载地址
:param url: 节目主页
:return: list，每个元素保存一个下载地址
"""
download_url_list = []
try:
    soup = BeautifulSoup(requests.get(url).content)
except Exception, e:
    print e
for item in soup.find_all('a', class_='button fa fa-download'):
    download_url_list.append(os.path.join(url, item['href']))
return download_url_list
```

def save_audio(url, path, filename):

``` 
"""
保存音频文件
:param url: 音频文件路径
:param path: 保存路径
:param filename: 文件名
"""
if not os.path.isdir(path):
    os.makedirs(path)
with open(os.path.join(path, filename), 'wb') as fw:
    try:
        fw.write(requests.get(url).content)
    except Exception, e:
        print e
```

def main():

``` 
path = '/Users/lufo/Music/IPN/'
podcast_list = get_podcast_list()
for podcast_url in podcast_list:
    save_path = os.path.join(path, podcast_url.split('/')[-2])
    download_url_list = get_download_url_list(podcast_url)
    for i, url in enumerate(download_url_list):
        save_audio(url, save_path, str(i) + '.mp3')
```

if __name__ == '__main__':

``` 
main()
```

{% endhighlight %}