---
title: ASR7:word to phoneme
layout: post
tags:
  - speech_recognition
---

之前我们一直都是在以word为单位做语音识别，一个word有5个states，但是根据[zipf's law](https://en.wikipedia.org/wiki/Zipf%27s_law)，少数词会大量出现，如the，a之类的，而大量的词只出现了几次甚至没有出现过，然而这些较少出现的词往往包含更大的信息量，这就造成了训练数据不足的问题。为了解决这个问题，我们从以word为单位转为以phoneme为单位。

word有成千上万个，而phoneme只有几十个，所以以phoneme为单位就不存在很多phoneme没有出现过的问题，以phoneme为单位训练就可以了，但是现在问题又来了，同一个phoneme在上下文不同时特征是差别很大的：

![](/media/files/2015/08/02.png)

为了解决这个问题提出了diphone，它不是用一个phoneme作为基本单位，而是用两个phoneme之间的那段作为语音识别的基本单位，下图可以看到，即使上下文不同，两个相同的phoneme之间的信息还是很相似的：

![](/media/files/2015/08/03.png)

这样做会提高模型的准确度，但会增加模型的复杂度，因为原来只有N种phoneme现在有N^2种diphone，同时也会令zipf's law带来的问题再次出现。

更进一步还可以使用triphone，它还是用一个phoneme作为基本单位，但是考虑了上下文信息，1，2，3分别代表三个phoneme，123中的2和321中的2是两个不同的phoneme，因为它们上下文不同。triphone比diphone更复杂，它将diphone的优点和缺点都扩大了。

总之，以word为单位当训练数据充足的时候效果是很好的，但是词汇量很大是往往找不到充足的训练数据，所以像识别如电话号码这种词典很小的应用时最好以word为单位识别。以phoneme为单位可以解决训练数据不足的问题，当词典较大时可以使用triphone模型。

现在问题来了，每个triphone对应HMM中的3-5个states，每个state又对应一个GMM，参数太多，并且很多triphone训练数据很少，怎么解决这些问题那？答案是参数共享。我们可以把那些很相似的高斯模型分为一类，共享参数，这样就减少了参数，同时共享了数据。可以聚类或者用决策树分类。对于没见过的triphone，可以用它对应的单个phoneme的数据训练。
